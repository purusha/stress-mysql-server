package runner.contactlab.com;

import java.beans.PropertyVetoException;
import java.io.File;
import java.io.IOException;
import java.util.List;
import java.util.Queue;
import java.util.Set;
import java.util.concurrent.ConcurrentLinkedQueue;
import java.util.concurrent.Executors;
import java.util.concurrent.ScheduledExecutorService;
import java.util.concurrent.ScheduledFuture;
import java.util.concurrent.TimeUnit;

import javax.sql.DataSource;

import script.contactlab.com.ApplicationCheckPointCounter;
import script.contactlab.com.ApplicationParameter;
import script.contactlab.com.LoadDataFileNameRepository;
import script.contactlab.com.PartialResultWriter;
import script.contactlab.com.PropertyLoadDataFileNameRepository;
import script.contactlab.com.SearchLoadDataStatement;
import script.contactlab.com.SplitGeneralQueryLogFile;
import script.contactlab.com.TimerConnectionAggregator;

import com.google.inject.Inject;

public class DelayedApplicationRunner extends ApplicationRunner {
	
	private LoadDataFileNameRepository repository;
	private ApplicationCheckPointCounter checkPoint;

	@Inject
	public DelayedApplicationRunner(final LoadDataFileNameRepository repository, final ApplicationCheckPointCounter checkPoint) {
		this.repository = repository;
		this.checkPoint = checkPoint;
	}

	@Override
	protected void realRun(final ApplicationParameter params) throws Exception {
		logger.info("Starting ...");		
		final String filesPath = params.getPathOfPayload() + SUB_PATH_FILES;
		
		//make dir /files and empty if exist
		final File t = new File(filesPath);		
		delete(t);			
		t.mkdir();
		
		System.out.println("Start splitter of general query log file");
		final List<TimerConnectionAggregator> data = new SplitGeneralQueryLogFile().run(params.generalQueryLogPath(), filesPath);
		
		System.out.println("Start search LOAD DATA into general query log file");
		final Set<Integer> idsWithLoadData = new SearchLoadDataStatement().run(params.generalQueryLogPath());
		
		if (idsWithLoadData.isEmpty()) {
			System.out.println("Start schedule of " + data.size() + " connection's");
			schedule(params.getNumberOfThread(), data, filesPath, null, params.getDatabaseServer(), params.getPathOfPayload());											
		} else {			
			logger.info("Start searching of real file name of LOAD DATA: " + idsWithLoadData.size());
			((PropertyLoadDataFileNameRepository)repository).run(idsWithLoadData, params.getPathOfRealFileNames());
			
			for (TimerConnectionAggregator tca : data) {				
				for (Integer i : tca.getIds()) {
					if (repository.containsKey(i)) {
						tca.addLoadData(i, repository.get(i));
					}					
				}
			}
			
			System.out.println("Start schedule of " + data.size() + " connection's and " + idsWithLoadData.size() + " load data");
			schedule(params.getNumberOfThread(), data, filesPath, params.loadDataDirPath(), params.getDatabaseServer(), params.getPathOfPayload()); 	
		}
	}
	
	private void delete(File file) throws IOException {
		if (file.exists() && file.isDirectory()) {
			// directory is empty, then delete it
			if (file.list().length == 0) {
				file.delete();
			} else {
				// list all the directory contents
				final String files[] = file.list();

				for (String temp : files) {
					// construct the file structure
					final File fileDelete = new File(file, temp);

					// recursive delete
					delete(fileDelete);
				}

				// check the directory again, if empty then delete it
				if (file.list().length == 0) {
					file.delete();
				}
			}
		} else {
			// if file, then delete it
			file.delete();
		}
	}
	
	private void schedule(int numberOfThread, List<TimerConnectionAggregator> data, String filesPath, String loadDatasPath, String dbHostName, String generalLogDirPath) {
		checkPoint.totalNumber(data.size());
		final Queue<ScheduledFuture<PayloadAsync>> futureData = new ConcurrentLinkedQueue<ScheduledFuture<PayloadAsync>>();						

		addHookForCancelTask(futureData);
		
		final ScheduledExecutorService pool = Executors.newScheduledThreadPool(numberOfThread);
		
		try {
			final DataSource ds = buildDataSource(dbHostName, numberOfThread);			
			long current = 0;
			
			for (TimerConnectionAggregator tca : data) {
				current += tca.getDelay();
				
				futureData.add(
					pool.schedule(
						new MyCallable(tca, filesPath, loadDatasPath, ds), 
						current, 
						TimeUnit.MILLISECONDS
					)
				);
			}			
		} catch (PropertyVetoException e) {
			logger.error(null, e);
		}
		
		logger.info("thread pool shutdown");
		pool.shutdown();		
		
		//XXX thread pool for write partial report 						
		final ScheduledExecutorService scheduler = Executors.newScheduledThreadPool(1);
		 		
		final PartialResultWriter prw = new PartialResultWriter(futureData, generalLogDirPath, checkPoint);		
		final ScheduledFuture<?> sf = scheduler.scheduleAtFixedRate(prw, 60, 60, TimeUnit.SECONDS);
		
		scheduler.schedule(new Runnable() {
			public void run() {
				if (prw.isEnd()) {
					logger.error("shutdown partial result writer !!?");
					sf.cancel(false);
					
					scheduler.shutdown();
				}
			}
		}, 5, TimeUnit.MINUTES);
		
		try {
			logger.info("thread pool awaitTermination");
			pool.awaitTermination(Long.MAX_VALUE, TimeUnit.SECONDS);
			scheduler.awaitTermination(Long.MAX_VALUE, TimeUnit.MINUTES);
		} catch (InterruptedException e) {
			logger.error(null, e);
		}
	}
	
}
