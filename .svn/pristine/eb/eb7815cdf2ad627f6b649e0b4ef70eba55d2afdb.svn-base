package runner.contactlab.com;

import java.io.BufferedReader;
import java.io.File;
import java.io.FileReader;
import java.io.IOException;
import java.util.List;
import java.util.Queue;
import java.util.Set;
import java.util.concurrent.ConcurrentLinkedQueue;
import java.util.concurrent.Executors;
import java.util.concurrent.ScheduledExecutorService;
import java.util.concurrent.ScheduledFuture;
import java.util.concurrent.TimeUnit;

import os.contactlab.com.LoadDataFileNameRepository;
import os.contactlab.com.SearchLoadDataStatement;
import print.contactlab.com.PartialResultWriter;
import script.contactlab.com.ApplicationCheckPointCounter;
import script.contactlab.com.ApplicationParameter;
import script.contactlab.com.MyCallable;
import script.contactlab.com.PayloadAsync;
import script.contactlab.com.TimerConnectionAggregator;

import com.google.common.collect.Lists;
import com.google.inject.Inject;
import com.mchange.v2.c3p0.PooledDataSource;

public class DelayedApplicationRunner extends ApplicationRunner {
	
	private LoadDataFileNameRepository repository;
	private ApplicationCheckPointCounter checkPoint;

	@Inject
	public DelayedApplicationRunner(final LoadDataFileNameRepository repository, final ApplicationCheckPointCounter checkPoint) {
		this.repository = repository;
		this.checkPoint = checkPoint;
	}

	@Override
	protected void realRun(final ApplicationParameter params) throws Exception {
		logger.info("Starting ...");		
		final String filesPath = params.getPathOfPayload() + SUB_PATH_FILES;
				
		logger.info("Start search LOAD DATA into general query log file");
		final Set<Integer> idsWithLoadData = new SearchLoadDataStatement().run(params.generalQueryLogPath());
		
		logger.info("Start load file name of Connections");
		final List<Integer> connectionFileNames = retriveConnectionFiles(new File(filesPath));
		
		final List<TimerConnectionAggregator>  tcas = Lists.newArrayList();			
//		for (Integer i : connectionFileNames) {
//			//tcas.add(new TimerConnectionAggregator(NumberUtils.LONG_ZERO, Sets.newHashSet(i)));
//			
//			readState(filesPath + i);
//		}		
		
		if (idsWithLoadData.isEmpty()) {
			System.out.println("Start schedule of " + connectionFileNames.size() + " connection's");
			schedule(params.getNumberOfThread(), tcas, filesPath, null, params.getDatabaseServer(), params.getPathOfPayload());											
		} else {			
//			logger.info("Start searching of real file name of LOAD DATA: " + idsWithLoadData.size());
//			((PropertyLoadDataFileNameRepository)repository).run(idsWithLoadData, params.getPathOfRealFileNames());
//			
//			for (TimerConnectionAggregator tca : tcas) {				
//				for (Integer i : tca.getIds()) {
//					if (repository.containsKey(i)) {
//						tca.addLoadData(i, repository.get(i));
//					}					
//				}
//			}
//			
//			logger.info("Start schedule of " + connectionFileNames.size() + " connection's and " + idsWithLoadData.size() + " load data");
//			schedule(params.getNumberOfThread(), tcas, filesPath, params.loadDataDirPath(), params.getDatabaseServer(), params.getPathOfPayload()); 	
		}
	}
	
	private String readState(String fileName) throws IOException {
        BufferedReader reader = null;
        try {
            reader = new BufferedReader(new FileReader(fileName));
            
            return reader.readLine();
        } finally {
            if (reader != null) {
            	reader.close();
            }                
        }
    }	
	
//	@Override
//	protected void realRun(final ApplicationParameter params) throws Exception {
//		logger.info("Starting ...");		
//		final String filesPath = params.getPathOfPayload() + SUB_PATH_FILES;
//		
//		//make dir /files and empty if exist
//		final File t = new File(filesPath);		
//		delete(t);			
//		t.mkdir();
//		
//		System.out.println("Start splitter of general query log file");
//		final List<TimerConnectionAggregator> data = new SplitGeneralQueryLogFile().run(params.generalQueryLogPath(), filesPath);
//		
//		System.out.println("Start search LOAD DATA into general query log file");
//		final Set<Integer> idsWithLoadData = new SearchLoadDataStatement().run(params.generalQueryLogPath());
//		
//		if (idsWithLoadData.isEmpty()) {
//			System.out.println("Start schedule of " + data.size() + " connection's");
//			schedule(params.getNumberOfThread(), data, filesPath, null, params.getDatabaseServer(), params.getPathOfPayload());											
//		} else {			
//			logger.info("Start searching of real file name of LOAD DATA: " + idsWithLoadData.size());
//			((PropertyLoadDataFileNameRepository)repository).run(idsWithLoadData, params.getPathOfRealFileNames());
//			
//			for (TimerConnectionAggregator tca : data) {				
//				for (Integer i : tca.getIds()) {
//					if (repository.containsKey(i)) {
//						tca.addLoadData(i, repository.get(i));
//					}					
//				}
//			}
//			
//			System.out.println("Start schedule of " + data.size() + " connection's and " + idsWithLoadData.size() + " load data");
//			schedule(params.getNumberOfThread(), data, filesPath, params.loadDataDirPath(), params.getDatabaseServer(), params.getPathOfPayload()); 	
//		}
//	}
	
//	private void delete(File file) throws IOException {
//		if (file.exists() && file.isDirectory()) {
//			// directory is empty, then delete it
//			if (file.list().length == 0) {
//				file.delete();
//			} else {
//				// list all the directory contents
//				final String files[] = file.list();
//
//				for (String temp : files) {
//					// construct the file structure
//					final File fileDelete = new File(file, temp);
//
//					// recursive delete
//					delete(fileDelete);
//				}
//
//				// check the directory again, if empty then delete it
//				if (file.list().length == 0) {
//					file.delete();
//				}
//			}
//		} else {
//			// if file, then delete it
//			file.delete();
//		}
//	}
	
	private void schedule(int numberOfThread, List<TimerConnectionAggregator> data, String filesPath, String loadDatasPath, String dbHostName, String generalLogDirPath) {
		checkPoint.totalNumber(data.size());
		
		final Queue<ScheduledFuture<PayloadAsync>> futureData = new ConcurrentLinkedQueue<ScheduledFuture<PayloadAsync>>();						
		final ScheduledExecutorService pool = Executors.newScheduledThreadPool(numberOfThread);
		final PooledDataSource ds = buildDataSource(dbHostName, numberOfThread);
		
		addHookForCancelTask(futureData, ds);				
		
		long current = 0;		
		for (TimerConnectionAggregator tca : data) {
			current += tca.getDelay();
			
			futureData.add(
				pool.schedule(
					new MyCallable(tca, filesPath, loadDatasPath, ds), 
					current, 
					TimeUnit.MILLISECONDS
				)
			);
		}			
		
		logger.info("thread pool shutdown");
		pool.shutdown();		
		
		//XXX thread pool for write partial report 						
		final ScheduledExecutorService scheduler = Executors.newScheduledThreadPool(1);
		 		
		final PartialResultWriter prw = new PartialResultWriter(futureData, generalLogDirPath, checkPoint);		
		final ScheduledFuture<?> sf = scheduler.scheduleAtFixedRate(prw, 60, 60, TimeUnit.SECONDS);
		
		scheduler.schedule(new Runnable() {
			public void run() {
				if (prw.isEnd()) {
					logger.error("shutdown partial result writer !!?");
					sf.cancel(false);
					
					scheduler.shutdown();
				}
			}
		}, 5, TimeUnit.MINUTES);
		
		try {
			logger.info("thread pool awaitTermination");
			pool.awaitTermination(Long.MAX_VALUE, TimeUnit.MINUTES);			
			scheduler.awaitTermination(10l, TimeUnit.MINUTES);
		} catch (InterruptedException e) {
			logger.error(null, e);
		}
	}
	
}
